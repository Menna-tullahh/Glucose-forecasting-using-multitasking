{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.time_series_prep import *\n",
    "import pandas as pd\n",
    "from models.shared_layer import *\n",
    "from torchviz import make_dot\n",
    "from torchsummary import summary\n",
    "from src.data_preprocessing import *\n",
    "from src.visualizations import *\n",
    "from src.global_configs import *\n",
    "from src.time_series_prep import *\n",
    "import logging\n",
    "from src.post_processing import *\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics import r2_score\n",
    "torch.set_printoptions(precision=10)  # Set precision to 10 decimal places\n",
    "\n",
    "# Initialize logger\n",
    "logging.basicConfig(\n",
    "    filename='training.log',  # File where logs will be saved\n",
    "    level=logging.INFO,  # Set logging level to INFO\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',  # Log format\n",
    "    # filemode='w'  # Overwrite log file on each run\n",
    ")\n",
    "logger = logging.getLogger()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "scaler = process_all_csv_files(input_folder, output_folder_train, timestamp_col='ts', freq='5min', agg_func='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type = 'shared-layer'\n",
    "mask_scaled = 139.15895187396728\n",
    "prediction_horizons = [3, 6, 9, 12, 15, 18]\n",
    "abs_patients_errors_PHs =  {key: [] for key in prediction_horizons}\n",
    "squared_patients_errors_PHs =  {key: [] for key in prediction_horizons}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X (features): (12, 13612, 12)\n",
      "Shape of y (targets): (12, 13612)\n",
      "Shape of X_test (features): (12, 3933, 12)\n",
      "Shape of y_test (targets): (12, 3933)\n"
     ]
    }
   ],
   "source": [
    "train_loader, validation_loader, all_train_loader, test_loader, input_shape, input_shape_test, output_shape, output_shape_test =  prepare_data_loader(\n",
    "                                                                                        window_size,BATCH_SIZE, 6,\n",
    "                                                                                        model_type, split_ratio = 0.7, df = None, df_test = None, output_folder_train=output_folder_train, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_all_train_read =  SharedLayerModelWithAttention(input_shape =input_shape , output_shape=output_shape)\n",
    "model_all_train_read.load_state_dict(torch.load(f'saved_models//model_{model_type}_attention_{str(6)}_{0}.pth',weights_only=False))\n",
    "model_all_train_read.to(device)\n",
    "model_all_train_read.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_all_batches, targets_all_batches = model_prediction(model_all_train_read,test_loader, device, model_type)\n",
    "# predictions_flat = np.exp(scaler.inverse_transform(torch.cat(outputs_all_batches, dim=0).cpu()))\n",
    "# ground_truth_flat = np.exp(scaler.inverse_transform(torch.cat(targets_all_batches, dim=0).cpu()))\n",
    "# Convert tensors to CPU and concatenate batches\n",
    "# Convert tensors to CPU and concatenate batches\n",
    "# Convert tensors to CPU and concatenate batches\n",
    "predictions_tensor = torch.cat(outputs_all_batches, dim=0).cpu()\n",
    "ground_truth_tensor = torch.cat(targets_all_batches, dim=0).cpu()\n",
    "\n",
    "# Mask zero values\n",
    "predictions_mask = (predictions_tensor != 0)\n",
    "ground_truth_mask = (ground_truth_tensor != 0)\n",
    "\n",
    "# Initialize transformed tensors with zeros (to preserve zeros)\n",
    "predictions_transformed = torch.zeros_like(predictions_tensor)\n",
    "ground_truth_transformed = torch.zeros_like(ground_truth_tensor)\n",
    "\n",
    "# Apply the scaler.inverse_transform only to non-zero values and convert back to torch tensor\n",
    "if predictions_mask.any():\n",
    "    non_zero_predictions = predictions_tensor[predictions_mask].unsqueeze(-1).numpy()\n",
    "    inverse_transformed_predictions = scaler.inverse_transform(non_zero_predictions).squeeze()\n",
    "    predictions_transformed[predictions_mask] = torch.exp(torch.tensor(\n",
    "        inverse_transformed_predictions, dtype=predictions_tensor.dtype\n",
    "    ))\n",
    "\n",
    "if ground_truth_mask.any():\n",
    "    non_zero_ground_truth = ground_truth_tensor[ground_truth_mask].unsqueeze(-1).numpy()\n",
    "    inverse_transformed_ground_truth = scaler.inverse_transform(non_zero_ground_truth).squeeze()\n",
    "    ground_truth_transformed[ground_truth_mask] = torch.exp(torch.tensor(\n",
    "        inverse_transformed_ground_truth, dtype=ground_truth_tensor.dtype\n",
    "    ))\n",
    "\n",
    "ground_truth_flat = ground_truth_transformed\n",
    "predictions_flat= predictions_transformed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9052676493265647,\n",
       " 0.8325252140904036,\n",
       " 0.9180502188847743,\n",
       " 0.8470163131560583,\n",
       " 0.8282279702485816,\n",
       " 0.811296222467086,\n",
       " 0.874703739073241,\n",
       " 0.879338271057478,\n",
       " 0.8708817487664965,\n",
       " 0.8191915741983191,\n",
       " 0.8542529400942458,\n",
       " 0.8736133850785143]"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#R2 Score \n",
    "\n",
    "# Calculate R2 for each patient (each column)\n",
    "r2_scores = []\n",
    "for patient_idx in range(np.array(predictions_flat).shape[1]):  # Iterate over columns (patients)\n",
    "    pred = predictions_flat[:, patient_idx]  # Get predictions for this patient\n",
    "    true = ground_truth_flat[:, patient_idx]  # Get ground truth for this patient\n",
    "    non_zero_mask = true != 0\n",
    "    pred = pred[non_zero_mask]\n",
    "    true = true[non_zero_mask]\n",
    "    r2 = r2_score(true, pred)\n",
    "    r2_scores.append(r2)\n",
    "r2_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patient 1 MADP: 7.46%\n",
      "Patient 2 MADP: 10.01%\n",
      "Patient 3 MADP: 6.03%\n",
      "Patient 4 MADP: 8.61%\n",
      "Patient 5 MADP: 10.33%\n",
      "Patient 6 MADP: 11.01%\n",
      "Patient 7 MADP: 9.52%\n",
      "Patient 8 MADP: 8.24%\n",
      "Patient 9 MADP: 8.75%\n",
      "Patient 10 MADP: 9.56%\n",
      "Patient 11 MADP: 9.70%\n",
      "Patient 12 MADP: 8.90%\n"
     ]
    }
   ],
   "source": [
    "madp_scores = []\n",
    "for patient_idx in range(predictions_flat.shape[1]):  # Iterate over columns (patients)\n",
    "    pred = predictions_flat[:, patient_idx]  # Get predictions for this patient\n",
    "    true = ground_truth_flat[:, patient_idx]  # Get ground truth for this patient\n",
    "    \n",
    "    # Avoid division by zero by excluding cases where true value is zero\n",
    "    non_zero_mask = true != 0\n",
    "    pred = pred[non_zero_mask]\n",
    "    true = true[non_zero_mask]\n",
    "    \n",
    "    madp = (abs((true - pred) / true)).mean() * 100  # Calculate MADP\n",
    "    madp_scores.append(madp)\n",
    "# Step 3: Print MADP scores for each patient\n",
    "for idx, madp in enumerate(madp_scores):\n",
    "    print(f\"Patient {idx+1} MADP: {madp:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.010224"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(madp_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def calculate_zone_percentages(zones):\n",
    "    total_points = sum(zones)\n",
    "    if total_points == 0:\n",
    "        return [0] * len(zones)  # Avoid division by zero if there are no points\n",
    "    return [(count / total_points) * 100 for count in zones]\n",
    "\n",
    "#This function takes in the reference values and the prediction values as lists and returns a list with each index corresponding to the total number\n",
    "#of points within that zone (0=A, 1=B, 2=C, 3=D, 4=E) and the plot\n",
    "def clarke_error_grid(ref_values, pred_values, title_string, mask_value):\n",
    "    if mask_value is not None:\n",
    "        filtered_data = [(ref, pred) for ref, pred in zip(ref_values, pred_values) if ref != mask_value and pred != mask_value]\n",
    "\n",
    "        ref_values, pred_values = zip(*filtered_data) if filtered_data else ([], [])\n",
    "    #Checking to see if the lengths of the reference and prediction arrays are the same\n",
    "    assert (len(ref_values) == len(pred_values)), \"Unequal number of values (reference : {}) (prediction : {}).\".format(len(ref_values), len(pred_values))\n",
    "\n",
    "    #Checks to see if the values are within the normal physiological range, otherwise it gives a warning\n",
    "    # if max(ref_values) > 400 or max(pred_values) > 400:\n",
    "    #     print \"Input Warning: the maximum reference value {} or the maximum prediction value {} exceeds the normal physiological range of glucose (<400 mg/dl).\".format(max(ref_values), max(pred_values))\n",
    "    # if min(ref_values) < 0 or min(pred_values) < 0:\n",
    "    #     print \"Input Warning: the minimum reference value {} or the minimum prediction value {} is less than 0 mg/dl.\".format(min(ref_values),  min(pred_values))\n",
    "\n",
    "    #Clear plot\n",
    "    plt.clf()\n",
    "\n",
    "    #Set up plot\n",
    "    plt.scatter(ref_values, pred_values, marker='o', color='black', s=3)\n",
    "    plt.title(title_string + \" Clarke Error Grid\")\n",
    "    plt.xlabel(\"Reference Concentration (mg/dl)\")\n",
    "    plt.ylabel(\"Prediction Concentration (mg/dl)\")\n",
    "    plt.xticks([0, 50, 100, 150, 200, 250, 300, 350, 400])\n",
    "    plt.yticks([0, 50, 100, 150, 200, 250, 300, 350, 400])\n",
    "    plt.gca().set_facecolor('white')\n",
    "\n",
    "    #Set axes lengths\n",
    "    plt.gca().set_xlim([0, 400])\n",
    "    plt.gca().set_ylim([0, 400])\n",
    "    plt.gca().set_aspect((400)/(400))\n",
    "\n",
    "    #Plot zone lines\n",
    "    plt.plot([0,400], [0,400], ':', c='black')                      #Theoretical 45 regression line\n",
    "    plt.plot([0, 175/3], [70, 70], '-', c='black')\n",
    "    #plt.plot([175/3, 320], [70, 400], '-', c='black')\n",
    "    plt.plot([175/3, 400/1.2], [70, 400], '-', c='black')           #Replace 320 with 400/1.2 because 100*(400 - 400/1.2)/(400/1.2) =  20% error\n",
    "    plt.plot([70, 70], [84, 400],'-', c='black')\n",
    "    plt.plot([0, 70], [180, 180], '-', c='black')\n",
    "    plt.plot([70, 290],[180, 400],'-', c='black')\n",
    "    # plt.plot([70, 70], [0, 175/3], '-', c='black')\n",
    "    plt.plot([70, 70], [0, 56], '-', c='black')                     #Replace 175.3 with 56 because 100*abs(56-70)/70) = 20% error\n",
    "    # plt.plot([70, 400],[175/3, 320],'-', c='black')\n",
    "    plt.plot([70, 400], [56, 320],'-', c='black')\n",
    "    plt.plot([180, 180], [0, 70], '-', c='black')\n",
    "    plt.plot([180, 400], [70, 70], '-', c='black')\n",
    "    plt.plot([240, 240], [70, 180],'-', c='black')\n",
    "    plt.plot([240, 400], [180, 180], '-', c='black')\n",
    "    plt.plot([130, 180], [0, 70], '-', c='black')\n",
    "\n",
    "    #Add zone titles\n",
    "    plt.text(30, 15, \"A\", fontsize=15)\n",
    "    plt.text(370, 260, \"B\", fontsize=15)\n",
    "    plt.text(280, 370, \"B\", fontsize=15)\n",
    "    plt.text(160, 370, \"C\", fontsize=15)\n",
    "    plt.text(160, 15, \"C\", fontsize=15)\n",
    "    plt.text(30, 140, \"D\", fontsize=15)\n",
    "    plt.text(370, 120, \"D\", fontsize=15)\n",
    "    plt.text(30, 370, \"E\", fontsize=15)\n",
    "    plt.text(370, 15, \"E\", fontsize=15)\n",
    "# ax.set_yticklabels(ax.get_yticklabels(), rotation=0)\n",
    "    plt.xticks(rotation=45)\n",
    "    #Statistics from the data\n",
    "    zone = [0] * 5\n",
    "    for i in range(len(ref_values)):\n",
    "        if (ref_values[i] <= 70 and pred_values[i] <= 70) or (pred_values[i] <= 1.2*ref_values[i] and pred_values[i] >= 0.8*ref_values[i]):\n",
    "            zone[0] += 1    #Zone A\n",
    "\n",
    "        elif (ref_values[i] >= 180 and pred_values[i] <= 70) or (ref_values[i] <= 70 and pred_values[i] >= 180):\n",
    "            zone[4] += 1    #Zone E\n",
    "\n",
    "        elif ((ref_values[i] >= 70 and ref_values[i] <= 290) and pred_values[i] >= ref_values[i] + 110) or ((ref_values[i] >= 130 and ref_values[i] <= 180) and (pred_values[i] <= (7/5)*ref_values[i] - 182)):\n",
    "            zone[2] += 1    #Zone C\n",
    "        elif (ref_values[i] >= 240 and (pred_values[i] >= 70 and pred_values[i] <= 180)) or (ref_values[i] <= 175/3 and pred_values[i] <= 180 and pred_values[i] >= 70) or ((ref_values[i] >= 175/3 and ref_values[i] <= 70) and pred_values[i] >= (6/5)*ref_values[i]):\n",
    "            zone[3] += 1    #Zone D\n",
    "        else:\n",
    "            zone[1] += 1    #Zone B\n",
    "    return plt, zone, calculate_zone_percentages(zone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ground_truth_flat' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m clarke_error_grid(\u001b[43mground_truth_flat\u001b[49m\u001b[38;5;241m.\u001b[39mflatten(), predictions_flat\u001b[38;5;241m.\u001b[39mflatten(), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m, mask_value)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'ground_truth_flat' is not defined"
     ]
    }
   ],
   "source": [
    "clarke_error_grid(ground_truth_flat.flatten(), predictions_flat.flatten(), \"\", mask_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many hypo-hyper glycemia events are predicted wrong (missed) Zone D\n",
    "# how many hypo-hyper glycemia covered ? No \n",
    "# how many normal event is perdicted in hyper-hypo?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Hyper/Hypoglycemia Events in Target (Adverse Events): 8500\n",
      "True Positives (Covered Events): 6323 (74.39%)\n",
      "False Negatives (Missed Events): 2177 (25.61%)\n",
      "False Positives (Incorrectly Predicted Events): 1238 (3.82%)\n",
      "True Negatives (Correctly Predicted Euglycemia): 22638 (69.92%)\n",
      "\n",
      "Matthews Correlation Coefficient (MCC): 0.7197291869936003\n"
     ]
    }
   ],
   "source": [
    "# import numpy as np\n",
    "# from sklearn.metrics import matthews_corrcoef\n",
    "\n",
    "\n",
    "# # Classify into binary categories\n",
    "# def classify_glucose(values):\n",
    "#     return np.where((values < 70) | (values > 180), 1, 0)\n",
    "# # Filter out cases where target is 0\n",
    "# valid_indices = ground_truth_flat.flatten() != 0  # Mask to exclude zeros in the target\n",
    "# filtered_target = ground_truth_flat.flatten()[valid_indices]\n",
    "# filtered_predicted = predictions_flat.flatten()[valid_indices]\n",
    "\n",
    "# target_binary = classify_glucose(filtered_target)\n",
    "# predicted_binary = classify_glucose(filtered_predicted)\n",
    "\n",
    "# # Calculate counts\n",
    "# true_positive = np.sum((target_binary == 1) & (predicted_binary == 1))  # Correctly predicted adverse events\n",
    "# false_negative = np.sum((target_binary == 1) & (predicted_binary == 0))  # Missed adverse events\n",
    "# false_positive = np.sum((target_binary == 0) & (predicted_binary == 1))  # Incorrectly predicted adverse events\n",
    "# true_negative = np.sum((target_binary == 0) & (predicted_binary == 0))  # Correctly predicted euglycemic events\n",
    "\n",
    "# # Total events\n",
    "# total_adverse_events = np.sum(target_binary)  # Total adverse events (hyper/hypoglycemia)\n",
    "# total_events = len(target_binary)  # Total valid events\n",
    "\n",
    "# # Calculate percentages\n",
    "# true_positive_percentage = (true_positive / total_adverse_events) * 100 if total_adverse_events > 0 else 0\n",
    "# false_negative_percentage = (false_negative / total_adverse_events) * 100 if total_adverse_events > 0 else 0\n",
    "# false_positive_percentage = (false_positive / total_events) * 100 if total_events > 0 else 0\n",
    "# true_negative_percentage = (true_negative / total_events) * 100 if total_events > 0 else 0\n",
    "\n",
    "# # Output results\n",
    "# print(\"Total Hyper/Hypoglycemia Events in Target (Adverse Events):\", total_adverse_events)\n",
    "# print(\"True Positives (Covered Events):\", true_positive, f\"({true_positive_percentage:.2f}%)\")\n",
    "# print(\"False Negatives (Missed Events):\", false_negative, f\"({false_negative_percentage:.2f}%)\")\n",
    "# print(\"False Positives (Incorrectly Predicted Events):\", false_positive, f\"({false_positive_percentage:.2f}%)\")\n",
    "# print(\"True Negatives (Correctly Predicted Euglycemia):\", true_negative, f\"({true_negative_percentage:.2f}%)\")\n",
    "\n",
    "# # Calculate MCC\n",
    "# mcc = matthews_corrcoef(target_binary, predicted_binary)\n",
    "# print()\n",
    "# print(\"Matthews Correlation Coefficient (MCC):\", mcc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperglycemia Metrics:\n",
      "  Total Hyperglycemia Events in Target: 7519\n",
      "  True Positives (Covered Events): 5975 (79.47%)\n",
      "  False Negatives (Missed Events): 1544 (20.53%)\n",
      "  False Positives (Incorrectly Predicted Events): 1040 (3.21%)\n",
      "  True Negatives (Correctly Predicted Non-Hyperglycemia): 23817 (73.56%)\n",
      "\n",
      "Hypoglycemia Metrics:\n",
      "  Total Hypoglycemia Events in Target: 981\n",
      "  True Positives (Covered Events): 348 (35.47%)\n",
      "  False Negatives (Missed Events): 633 (64.53%)\n",
      "  False Positives (Incorrectly Predicted Events): 198 (0.61%)\n",
      "  True Negatives (Correctly Predicted Non-Hypoglycemia): 31197 (96.36%)\n"
     ]
    }
   ],
   "source": [
    "# # Classify hyperglycemia (glucose > 180) and hypoglycemia (glucose < 70) separately\n",
    "# def classify_hyper(values):\n",
    "#     return np.where(values > 180, 1, 0)  # 1 for hyperglycemia, 0 otherwise\n",
    "\n",
    "# def classify_hypo(values):\n",
    "#     return np.where(values < 70, 1, 0)  # 1 for hypoglycemia, 0 otherwise\n",
    "\n",
    "# # Binary classifications for hyper and hypo events\n",
    "# target_hyper = classify_hyper(filtered_target)\n",
    "# predicted_hyper = classify_hyper(filtered_predicted)\n",
    "\n",
    "# target_hypo = classify_hypo(filtered_target)\n",
    "# predicted_hypo = classify_hypo(filtered_predicted)\n",
    "\n",
    "# # Calculate metrics for hyperglycemia\n",
    "# hyper_tp = np.sum((target_hyper == 1) & (predicted_hyper == 1))  # True Positives\n",
    "# hyper_fn = np.sum((target_hyper == 1) & (predicted_hyper == 0))  # False Negatives\n",
    "# hyper_fp = np.sum((target_hyper == 0) & (predicted_hyper == 1))  # False Positives\n",
    "# hyper_tn = np.sum((target_hyper == 0) & (predicted_hyper == 0))  # True Negatives\n",
    "\n",
    "# # Calculate metrics for hypoglycemia\n",
    "# hypo_tp = np.sum((target_hypo == 1) & (predicted_hypo == 1))  # True Positives\n",
    "# hypo_fn = np.sum((target_hypo == 1) & (predicted_hypo == 0))  # False Negatives\n",
    "# hypo_fp = np.sum((target_hypo == 0) & (predicted_hypo == 1))  # False Positives\n",
    "# hypo_tn = np.sum((target_hypo == 0) & (predicted_hypo == 0))  # True Negatives\n",
    "\n",
    "# # Total hyper/hypoglycemia events\n",
    "# total_hyper_events = np.sum(target_hyper)\n",
    "# total_hypo_events = np.sum(target_hypo)\n",
    "# total_events = len(filtered_target)\n",
    "\n",
    "# # Calculate percentages for hyperglycemia\n",
    "# hyper_tp_percentage = (hyper_tp / total_hyper_events) * 100 if total_hyper_events > 0 else 0\n",
    "# hyper_fn_percentage = (hyper_fn / total_hyper_events) * 100 if total_hyper_events > 0 else 0\n",
    "# hyper_fp_percentage = (hyper_fp / total_events) * 100 if total_events > 0 else 0\n",
    "# hyper_tn_percentage = (hyper_tn / total_events) * 100 if total_events > 0 else 0\n",
    "\n",
    "# # Calculate percentages for hypoglycemia\n",
    "# hypo_tp_percentage = (hypo_tp / total_hypo_events) * 100 if total_hypo_events > 0 else 0\n",
    "# hypo_fn_percentage = (hypo_fn / total_hypo_events) * 100 if total_hypo_events > 0 else 0\n",
    "# hypo_fp_percentage = (hypo_fp / total_events) * 100 if total_events > 0 else 0\n",
    "# hypo_tn_percentage = (hypo_tn / total_events) * 100 if total_events > 0 else 0\n",
    "\n",
    "# # Output results\n",
    "# print(\"Hyperglycemia Metrics:\")\n",
    "# print(\"  Total Hyperglycemia Events in Target:\", total_hyper_events)\n",
    "# print(\"  True Positives (Covered Events):\", hyper_tp, f\"({hyper_tp_percentage:.2f}%)\")\n",
    "# print(\"  False Negatives (Missed Events):\", hyper_fn, f\"({hyper_fn_percentage:.2f}%)\")\n",
    "# print(\"  False Positives (Incorrectly Predicted Events):\", hyper_fp, f\"({hyper_fp_percentage:.2f}%)\")\n",
    "# print(\"  True Negatives (Correctly Predicted Non-Hyperglycemia):\", hyper_tn, f\"({hyper_tn_percentage:.2f}%)\")\n",
    "\n",
    "# print(\"\\nHypoglycemia Metrics:\")\n",
    "# print(\"  Total Hypoglycemia Events in Target:\", total_hypo_events)\n",
    "# print(\"  True Positives (Covered Events):\", hypo_tp, f\"({hypo_tp_percentage:.2f}%)\")\n",
    "# print(\"  False Negatives (Missed Events):\", hypo_fn, f\"({hypo_fn_percentage:.2f}%)\")\n",
    "# print(\"  False Positives (Incorrectly Predicted Events):\", hypo_fp, f\"({hypo_fp_percentage:.2f}%)\")\n",
    "# print(\"  True Negatives (Correctly Predicted Non-Hypoglycemia):\", hypo_tn, f\"({hypo_tn_percentage:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperglycemia MCC (Manual): 3044.3550143950406\n",
      "Hyperglycemia MCC (sklearn): 0.7716052781887126\n",
      "Hypoglycemia MCC (Manual): 361.95416857453404\n",
      "Hypoglycemia MCC (sklearn): 0.4638417016761874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\menna\\AppData\\Local\\Temp\\ipykernel_33452\\2744117051.py:30: RuntimeWarning: overflow encountered in scalar multiply\n",
      "  (hyper_tp + hyper_fp) * (hyper_tp + hyper_fn) * (hyper_tn + hyper_fp) * (hyper_tn + hyper_fn)\n",
      "C:\\Users\\menna\\AppData\\Local\\Temp\\ipykernel_33452\\2744117051.py:37: RuntimeWarning: overflow encountered in scalar multiply\n",
      "  (hypo_tp + hypo_fp) * (hypo_tp + hypo_fn) * (hypo_tn + hypo_fp) * (hypo_tn + hypo_fn)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# # Classify hyperglycemia (glucose > 180) and hypoglycemia (glucose < 70) separately\n",
    "# def classify_hyper(values):\n",
    "#     return np.where(values > 180, 1, 0)  # 1 for hyperglycemia, 0 otherwise\n",
    "\n",
    "# def classify_hypo(values):\n",
    "#     return np.where(values < 70, 1, 0)  # 1 for hypoglycemia, 0 otherwise\n",
    "\n",
    "# # Binary classifications for hyper and hypo events\n",
    "# target_hyper = classify_hyper(filtered_target)\n",
    "# predicted_hyper = classify_hyper(filtered_predicted)\n",
    "\n",
    "# target_hypo = classify_hypo(filtered_target)\n",
    "# predicted_hypo = classify_hypo(filtered_predicted)\n",
    "\n",
    "# # Calculate metrics for hyperglycemia\n",
    "# hyper_tp = np.sum((target_hyper == 1) & (predicted_hyper == 1))  # True Positives\n",
    "# hyper_fn = np.sum((target_hyper == 1) & (predicted_hyper == 0))  # False Negatives\n",
    "# hyper_fp = np.sum((target_hyper == 0) & (predicted_hyper == 1))  # False Positives\n",
    "# hyper_tn = np.sum((target_hyper == 0) & (predicted_hyper == 0))  # True Negatives\n",
    "\n",
    "# # Calculate metrics for hypoglycemia\n",
    "# hypo_tp = np.sum((target_hypo == 1) & (predicted_hypo == 1))  # True Positives\n",
    "# hypo_fn = np.sum((target_hypo == 1) & (predicted_hypo == 0))  # False Negatives\n",
    "# hypo_fp = np.sum((target_hypo == 0) & (predicted_hypo == 1))  # False Positives\n",
    "# hypo_tn = np.sum((target_hypo == 0) & (predicted_hypo == 0))  # True Negatives\n",
    "\n",
    "# # Manual MCC calculation for hyperglycemia\n",
    "# hyper_mcc_numerator = (hyper_tp * hyper_tn) - (hyper_fp * hyper_fn)\n",
    "# hyper_mcc_denominator = np.sqrt(\n",
    "#     (hyper_tp + hyper_fp) * (hyper_tp + hyper_fn) * (hyper_tn + hyper_fp) * (hyper_tn + hyper_fn)\n",
    "# )\n",
    "# hyper_mcc = hyper_mcc_numerator / hyper_mcc_denominator if hyper_mcc_denominator > 0 else 0\n",
    "\n",
    "# # Manual MCC calculation for hypoglycemia\n",
    "# hypo_mcc_numerator = (hypo_tp * hypo_tn) - (hypo_fp * hypo_fn)\n",
    "# hypo_mcc_denominator = np.sqrt(\n",
    "#     (hypo_tp + hypo_fp) * (hypo_tp + hypo_fn) * (hypo_tn + hypo_fp) * (hypo_tn + hypo_fn)\n",
    "# )\n",
    "# hypo_mcc = hypo_mcc_numerator / hypo_mcc_denominator if hypo_mcc_denominator > 0 else 0\n",
    "\n",
    "# # Calculate MCC using sklearn for comparison\n",
    "# hyper_mcc_sklearn = matthews_corrcoef(target_hyper, predicted_hyper)\n",
    "# hypo_mcc_sklearn = matthews_corrcoef(target_hypo, predicted_hypo)\n",
    "\n",
    "# # Output results\n",
    "# print(\"Hyperglycemia MCC (Manual):\", hyper_mcc)\n",
    "# print(\"Hyperglycemia MCC (sklearn):\", hyper_mcc_sklearn)\n",
    "\n",
    "# print(\"Hypoglycemia MCC (Manual):\", hypo_mcc)\n",
    "# print(\"Hypoglycemia MCC (sklearn):\", hypo_mcc_sklearn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define adverse events consistently for both functions\n",
    "# def detect_events(values, hypo_threshold=70, hyper_threshold=180):\n",
    "#     \"\"\"Detect adverse and euglycemia events.\"\"\"\n",
    "#     adverse_events = (values < hypo_threshold) | (values > hyper_threshold)\n",
    "#     euglycemia_events = ~adverse_events\n",
    "#     return adverse_events, euglycemia_events\n",
    "# def calculate_coverage_and_false_alarms(predictions, ground_truth, hypo_threshold=70, hyper_threshold=180, mask_value=0):\n",
    "#     \"\"\"\n",
    "#     Calculate hypoglycemia and hyperglycemia coverage and false alarms for each patient,\n",
    "#     with robust handling of event detection and proper exclusion of masked values.\n",
    "#     \"\"\"\n",
    "#     hypo_coverage = []\n",
    "#     hyper_coverage = []\n",
    "#     hypo_false_alarm = []\n",
    "#     hyper_false_alarm = []\n",
    "\n",
    "#     total_hypo_correct = 0\n",
    "#     total_hypo_events = 0\n",
    "#     total_hyper_correct = 0\n",
    "#     total_hyper_events = 0\n",
    "\n",
    "#     for patient_idx in range(predictions.shape[1]):  # Iterate over each patient\n",
    "#         pred = predictions[:, patient_idx]\n",
    "#         true = ground_truth[:, patient_idx]\n",
    "\n",
    "#         # Exclude masked values\n",
    "#         valid_indices = (true != mask_value)\n",
    "#         pred = pred[valid_indices]\n",
    "#         true = true[valid_indices]\n",
    "\n",
    "#         # Detect hypoglycemia and hyperglycemia events\n",
    "#         true_hypo_events = (true < hypo_threshold)\n",
    "#         pred_hypo_events = (pred < hypo_threshold)\n",
    "\n",
    "#         true_hyper_events = (true > hyper_threshold)\n",
    "#         pred_hyper_events = (pred > hyper_threshold)\n",
    "\n",
    "#         # Hypoglycemia coverage\n",
    "#         correct_hypo_predictions = (pred_hypo_events & true_hypo_events).sum()\n",
    "#         hypo_event_count = true_hypo_events.sum()\n",
    "#         total_hypo_correct += correct_hypo_predictions\n",
    "#         total_hypo_events += hypo_event_count\n",
    "\n",
    "#         if hypo_event_count > 0:\n",
    "#             hypo_coverage.append(correct_hypo_predictions / hypo_event_count * 100)\n",
    "#         else:\n",
    "#             hypo_coverage.append(None)  # No hypoglycemia events for this patient\n",
    "\n",
    "#         # Hyperglycemia coverage\n",
    "#         correct_hyper_predictions = (pred_hyper_events & true_hyper_events).sum()\n",
    "#         hyper_event_count = true_hyper_events.sum()\n",
    "#         total_hyper_correct += correct_hyper_predictions\n",
    "#         total_hyper_events += hyper_event_count\n",
    "\n",
    "#         if hyper_event_count > 0:\n",
    "#             hyper_coverage.append(correct_hyper_predictions / hyper_event_count * 100)\n",
    "#         else:\n",
    "#             hyper_coverage.append(None)  # No hyperglycemia events for this patient\n",
    "\n",
    "#         # False alarms\n",
    "#         hypo_false_alarms = (pred_hypo_events & ~true_hypo_events).sum() / len(true) * 100\n",
    "#         hyper_false_alarms = (pred_hyper_events & ~true_hyper_events).sum() / len(true) * 100\n",
    "\n",
    "#         hypo_false_alarm.append(hypo_false_alarms)\n",
    "#         hyper_false_alarm.append(hyper_false_alarms)\n",
    "\n",
    "#     # Overall metrics\n",
    "#     overall_hypo_coverage = (total_hypo_correct / total_hypo_events * 100) if total_hypo_events > 0 else None\n",
    "#     overall_hyper_coverage = (total_hyper_correct / total_hyper_events * 100) if total_hyper_events > 0 else None\n",
    "\n",
    "#     overall_hypo_false_alarm = np.mean(hypo_false_alarm)\n",
    "#     overall_hyper_false_alarm = np.mean(hyper_false_alarm)\n",
    "\n",
    "#     return {\n",
    "#         \"hypo_coverage\": hypo_coverage,\n",
    "#         \"hyper_coverage\": hyper_coverage,\n",
    "#         \"overall_hypo_coverage\": overall_hypo_coverage,\n",
    "#         \"overall_hyper_coverage\": overall_hyper_coverage,\n",
    "#         \"overall_hypo_false_alarm\": overall_hypo_false_alarm,\n",
    "#         \"overall_hyper_false_alarm\": overall_hyper_false_alarm,\n",
    "#     }\n",
    "\n",
    "\n",
    "\n",
    "# def calculate_mcc(predictions, ground_truth, hypo_threshold=70, hyper_threshold=180, mask_value=0):\n",
    "#     \"\"\"\n",
    "#     Calculate Matthews Correlation Coefficient (MCC) with detailed debugging outputs.\n",
    "#     \"\"\"\n",
    "#     valid_indices = (ground_truth != mask_value) & (predictions != mask_value)\n",
    "#     pred = predictions[valid_indices]\n",
    "#     true = ground_truth[valid_indices]\n",
    "\n",
    "#     # Detect events consistently\n",
    "#     true_adverse, true_euglycemia = detect_events(true, hypo_threshold, hyper_threshold)\n",
    "#     pred_adverse, pred_euglycemia = detect_events(pred, hypo_threshold, hyper_threshold)\n",
    "#     print(true_adverse)\n",
    "#     print(pred_adverse)\n",
    "#     # Calculate TP, TN, FP, FN\n",
    "#     TP = np.sum(true_adverse & pred_adverse).astype(np.float64)\n",
    "#     TN = np.sum(true_euglycemia & pred_euglycemia).astype(np.float64)\n",
    "#     FP = np.sum(true_euglycemia & pred_adverse).astype(np.float64)\n",
    "#     FN = np.sum(true_adverse & pred_euglycemia).astype(np.float64)\n",
    "\n",
    "#     print(f\"TP: {TP}, TN: {TN}, FP: {FP}, FN: {FN}\")\n",
    "\n",
    "#     numerator = (TP * TN) - (FP * FN)\n",
    "#     denominator = np.sqrt((TP + FP) * (TP + FN) * (TN + FP) * (TN + FN))\n",
    "\n",
    "#     mcc = numerator / denominator if denominator > 0 else 0\n",
    "#     return mcc, {\"TP\": TP, \"TN\": TN, \"FP\": FP, \"FN\": FN}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Calculate MCC\n",
    "# mcc, confusion_matrix = calculate_mcc(predictions_flat, ground_truth_flat)\n",
    "\n",
    "# # Print Results\n",
    "# print(\"Matthews Correlation Coefficient (MCC):\", mcc)\n",
    "# print(\"Confusion Matrix:\", confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dict_overall = calculate_coverage_and_false_alarms(predictions_flat, ground_truth_flat)\n",
    "# dict_overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def detect_event_classification(values, hypo_threshold=70, hyper_threshold=180):\n",
    "#     \"\"\"\n",
    "#     Classify glucose values into hypoglycemia, hyperglycemia, or euglycemia.\n",
    "#     \"\"\"\n",
    "#     adverse_event = (values < hypo_threshold) | (values > hyper_threshold)  # Adverse events\n",
    "#     hypo_event = values < hypo_threshold  # Hypoglycemia\n",
    "#     hyper_event = values > hyper_threshold  # Hyperglycemia\n",
    "#     euglycemia_event = ~adverse_event  # Complement: Euglycemia\n",
    "#     return hypo_event, hyper_event, euglycemia_event\n",
    "\n",
    "# print(f\"Patient {patient_idx + 1}:\")\n",
    "# print(f\"  Total Hypoglycemia Events: {hypo_event_count}\")\n",
    "# print(f\"  Correct Hypoglycemia Predictions: {correct_hypo_predictions}\")\n",
    "# print(f\"  Total Hyperglycemia Events: {hyper_event_count}\")\n",
    "# print(f\"  Correct Hyperglycemia Predictions: {correct_hyper_predictions}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "biomedical-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
